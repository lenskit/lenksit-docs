<!DOCTYPE html>
<html class="no-js" lang="en"><!--<![endif]--><head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Top-N Evaluation — LensKit 0.7.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css">
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css">
    <link rel="index" title="Index" href="../genindex.html">
    <link rel="search" title="Search" href="../search.html">
    <link rel="next" title="Data Set Utilities" href="../datasets.html">
    <link rel="prev" title="Prediction Accuracy Metrics" href="predict-metrics.html"> 

<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="https://lkpy.lenskit.org/stable/evaluation/topn-metrics.html">



<script type="text/javascript" src="../_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'evaluation/topn-metrics'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> LensKit
          

          
          </a>

          
            
            
            
              <div class="version">
                0.7.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs">
    <input type="hidden" name="check_keywords" value="yes">
    <input type="hidden" name="area" value="default">
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../interfaces.html">Algorithm Interfaces</a></li>
<li class="toctree-l1"><a class="reference internal" href="../crossfold.html">Crossfold preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../batch.html">Batch-Running Recommenders</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Evaluating Recommender Output</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="predict-metrics.html">Prediction Accuracy Metrics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Top-<em>N</em> Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-lenskit.topn">Top-<em>N</em> Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-lenskit.metrics.topn">Metrics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#classification-metrics">Classification Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#ranked-list-metrics">Ranked List Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="#utility-metrics">Utility Metrics</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#loading-outputs">Loading Outputs</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Data Set Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../util.html">Utility Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../diagnostics.html">Errors and Diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../impl-tips.html">Algorithm Implementation Tips</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releases.html">Release Notes</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">LensKit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> »</li>
        
          <li><a href="index.html">Evaluating Recommender Output</a> »</li>
        
      <li>Top-<em>N</em> Evaluation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/lenskit/lkpy/blob/0.7.0/doc/evaluation/topn-metrics.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="top-n-evaluation">
<h1>Top-<em>N</em> Evaluation<a class="headerlink" href="#top-n-evaluation" title="Permalink to this headline">¶</a></h1>
<p>LensKit’s support for top-<em>N</em> evaluation is in two parts, because there are some
subtle complexities that make it more dfficult to get the right data in the right
place for computing metrics correctly.</p>
<div class="section" id="module-lenskit.topn">
<span id="top-n-analysis"></span><h2>Top-<em>N</em> Analysis<a class="headerlink" href="#module-lenskit.topn" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-lenskit.topn" title="lenskit.topn"><code class="xref py py-mod docutils literal notranslate"><span class="pre">lenskit.topn</span></code></a> module contains the utilities for carrying out top-<em>N</em>
analysis, in conjucntion with <a class="reference internal" href="../batch.html#lenskit.batch.recommend" title="lenskit.batch.recommend"><code class="xref py py-func docutils literal notranslate"><span class="pre">lenskit.batch.recommend()</span></code></a> and its wrapper
in <a class="reference internal" href="../batch.html#lenskit.batch.MultiEval" title="lenskit.batch.MultiEval"><code class="xref py py-class docutils literal notranslate"><span class="pre">lenskit.batch.MultiEval</span></code></a>.</p>
<p>The entry point to this is <a class="reference internal" href="#lenskit.topn.RecListAnalysis" title="lenskit.topn.RecListAnalysis"><code class="xref py py-class docutils literal notranslate"><span class="pre">RecListAnalysis</span></code></a>.  This class encapsulates
an analysis with one or more metrics, and can apply it to data frames of recommendations.
An analysis requires two data frames: the recommendation frame contains the recommendations
themselves, and the truth frame contains the ground truth data for the users.  The
analysis is flexible with regards to the columns that identify individual recommendation
lists; usually these will consist of a user ID, data set identifier, and algorithm
identifier(s), but the analysis is configurable and its defaults make minimal assumptions.
The recommendation frame does need an <code class="docutils literal notranslate"><span class="pre">item</span></code> column with the recommended item IDs,
and it should be in order within a single recommendation list.</p>
<p>The truth frame should contain (a subset of) the columns identifying recommendation
lists, along with <code class="docutils literal notranslate"><span class="pre">item</span></code> and, if available, <code class="docutils literal notranslate"><span class="pre">rating</span></code> (if no rating is provided,
the metrics that need a rating value will assume a rating of 1 for every item present).
It can contain other items that custom metrics may find useful as well.</p>
<p>For example, a recommendation frame may contain:</p>
<ul class="simple">
<li><p>DataSet</p></li>
<li><p>Partition</p></li>
<li><p>Algorithm</p></li>
<li><p>user</p></li>
<li><p>item</p></li>
<li><p>rank</p></li>
<li><p>score</p></li>
</ul>
<p>And the truth frame:</p>
<ul class="simple">
<li><p>DataSet</p></li>
<li><p>user</p></li>
<li><p>item</p></li>
<li><p>rating</p></li>
</ul>
<p>The analysis will use this truth as the relevant item data for measuring the accuracy of the
roecommendation lists.  Recommendations will be matched to test ratings by data set, user,
and item, using <a class="reference internal" href="#lenskit.topn.RecListAnalysis" title="lenskit.topn.RecListAnalysis"><code class="xref py py-class docutils literal notranslate"><span class="pre">RecListAnalysis</span></code></a> defaults.</p>
<dl class="class">
<dt id="lenskit.topn.RecListAnalysis">
<em class="property">class </em><code class="descclassname">lenskit.topn.</code><code class="descname">RecListAnalysis</code><span class="sig-paren">(</span><em>group_cols=None</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.topn.RecListAnalysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute one or more top-N metrics over recommendation lists.</p>
<p>This method groups the recommendations by the specified columns,
and computes the metric over each group.  The default set of grouping
columns is all columns <em>except</em> the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">item</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rank</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">score</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rating</span></code></p></li>
</ul>
<p>The truth frame, <code class="docutils literal notranslate"><span class="pre">truth</span></code>, is expected to match over (a subset of) the
grouping columns, and contain at least an <code class="docutils literal notranslate"><span class="pre">item</span></code> column.  If it also
contains a <code class="docutils literal notranslate"><span class="pre">rating</span></code> column, that is used as the users’ rating for
metrics that require it; otherwise, a rating value of 1 is assumed.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently, RecListAnalysis will silently drop users who received
no recommendations.  We are working on an ergonomic API for fixing
this problem.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>group_cols</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – The columns to group by, or <code class="docutils literal notranslate"><span class="pre">None</span></code> to use the default.</p>
</dd>
</dl>
<dl class="method">
<dt id="lenskit.topn.RecListAnalysis.add_metric">
<code class="descname">add_metric</code><span class="sig-paren">(</span><em>metric</em>, <em>*</em>, <em>name=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.topn.RecListAnalysis.add_metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a metric to the analysis.</p>
<p>A metric is a function of two arguments: the a single group of the recommendation
frame, and the corresponding truth frame.  The truth frame will be indexed by
item ID.  Many metrics are defined in <a class="reference internal" href="#module-lenskit.metrics.topn" title="lenskit.metrics.topn"><code class="xref py py-mod docutils literal notranslate"><span class="pre">lenskit.metrics.topn</span></code></a>; they are
re-exported from <a class="reference internal" href="#module-lenskit.topn" title="lenskit.topn"><code class="xref py py-mod docutils literal notranslate"><span class="pre">lenskit.topn</span></code></a> for convenience.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> – The metric to compute.</p></li>
<li><p><strong>name</strong> – The name to assign the metric. If not provided, the function name is used.</p></li>
<li><p><strong>**kwargs</strong> – Additional arguments to pass to the metric.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="lenskit.topn.RecListAnalysis.compute">
<code class="descname">compute</code><span class="sig-paren">(</span><em>recs</em>, <em>truth</em>, <em>*</em>, <em>include_missing=False</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.topn.RecListAnalysis.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the analysis.  Neither data frame should be meaningfully indexed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>recs</strong> (<a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.24.2)"><em>pandas.DataFrame</em></a>) – A data frame of recommendations.</p></li>
<li><p><strong>truth</strong> (<a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.24.2)"><em>pandas.DataFrame</em></a>) – A data frame of ground truth (test) data.</p></li>
<li><p><strong>include_missing</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – <code class="docutils literal notranslate"><span class="pre">True</span></code> to include users from truth missing from recs.
Matches are done via group columns that appear in both
<code class="docutils literal notranslate"><span class="pre">recs</span></code> and <code class="docutils literal notranslate"><span class="pre">truth</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The results of the analysis.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.24.2)">pandas.DataFrame</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-lenskit.metrics.topn">
<span id="metrics"></span><h2>Metrics<a class="headerlink" href="#module-lenskit.metrics.topn" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="#module-lenskit.metrics.topn" title="lenskit.metrics.topn"><code class="xref py py-mod docutils literal notranslate"><span class="pre">lenskit.metrics.topn</span></code></a> module contains metrics for evaluating top-<em>N</em>
recommendation lists.</p>
<div class="section" id="classification-metrics">
<h3>Classification Metrics<a class="headerlink" href="#classification-metrics" title="Permalink to this headline">¶</a></h3>
<p>These metrics treat the recommendation list as a classification of relevant items.</p>
<dl class="function">
<dt id="lenskit.metrics.topn.precision">
<code class="descclassname">lenskit.metrics.topn.</code><code class="descname">precision</code><span class="sig-paren">(</span><em>recs</em>, <em>truth</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.metrics.topn.precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute recommendation precision.</p>
</dd></dl>

<dl class="function">
<dt id="lenskit.metrics.topn.recall">
<code class="descclassname">lenskit.metrics.topn.</code><code class="descname">recall</code><span class="sig-paren">(</span><em>recs</em>, <em>truth</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.metrics.topn.recall" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute recommendation recall.</p>
</dd></dl>

</div>
<div class="section" id="ranked-list-metrics">
<h3>Ranked List Metrics<a class="headerlink" href="#ranked-list-metrics" title="Permalink to this headline">¶</a></h3>
<p>These metrics treat the recommendation list as a ranked list of items that may or may not
be relevant.</p>
<dl class="function">
<dt id="lenskit.metrics.topn.recip_rank">
<code class="descclassname">lenskit.metrics.topn.</code><code class="descname">recip_rank</code><span class="sig-paren">(</span><em>recs</em>, <em>truth</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.metrics.topn.recip_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the reciprocal rank of the first relevant item in a list of recommendations.</p>
<p>If no elements are relevant, the reciprocal rank is 0.</p>
</dd></dl>

</div>
<div class="section" id="utility-metrics">
<h3>Utility Metrics<a class="headerlink" href="#utility-metrics" title="Permalink to this headline">¶</a></h3>
<p>The NDCG function estimates a utility score for a ranked list of recommendations.</p>
<dl class="function">
<dt id="lenskit.metrics.topn.ndcg">
<code class="descclassname">lenskit.metrics.topn.</code><code class="descname">ndcg</code><span class="sig-paren">(</span><em>recs</em>, <em>truth</em>, <em>discount=&lt;ufunc 'log2'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.metrics.topn.ndcg" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the normalized discounted cumulative gain.</p>
<p>Discounted cumultative gain is computed as:</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
\mathrm{DCG}(L,u) &amp; = \sum_{i=1}^{|L|} \frac{r_{ui}}{d(i)}
\end{align*}\]</div>
<p>This is then normalized as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
\mathrm{nDCG}(L, u) &amp; = \frac{\mathrm{DCG}(L,u)}{\mathrm{DCG}(L_{\mathrm{ideal}}, u)}
\end{align*}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>recs</strong> – The recommendation list.</p></li>
<li><p><strong>truth</strong> – The user’s test data.</p></li>
<li><p><strong>discount</strong> (<em>ufunc</em>) – The rank discount function.  Each item’s score will be divided the discount of its rank,
if the discount is greater than 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<p>We also expose the internal DCG computation directly.</p>
<dl class="function">
<dt id="lenskit.metrics.topn._dcg">
<code class="descclassname">lenskit.metrics.topn.</code><code class="descname">_dcg</code><span class="sig-paren">(</span><em>scores</em>, <em>discount=&lt;ufunc 'log2'&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#lenskit.metrics.topn._dcg" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the Discounted Cumulative Gain of a series of recommended items with rating scores.
These should be relevance scores; they can be <span class="math notranslate nohighlight">\({0,1}\)</span> for binary relevance data.</p>
<p>This is not a true top-N metric, but is a utility function for other metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scores</strong> (<em>array-like</em>) – The utility scores of a list of recommendations, in recommendation order.</p></li>
<li><p><strong>discount</strong> (<em>ufunc</em>) – the rank discount function.  Each item’s score will be divided the discount of its rank,
if the discount is greater than 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the DCG of the scored items.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>double</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../datasets.html" class="btn btn-neutral float-right" title="Data Set Utilities" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="predict-metrics.html" class="btn btn-neutral float-left" title="Prediction Accuracy Metrics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr>

  <div role="contentinfo">
    <p>
        © Copyright 2018–2019 Boise State University
      
        <span class="commit">
          Revision <code>6514695d</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.7.0
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/latest/">latest</a></dd>
        
          <dd><a href="/en/stable/">stable</a></dd>
        
          <dd><a href="/en/0.7.0/">0.7.0</a></dd>
        
          <dd><a href="/en/0.6.1/">0.6.1</a></dd>
        
          <dd><a href="/en/0.6.0/">0.6.0</a></dd>
        
          <dd><a href="/en/0.5.0/">0.5.0</a></dd>
        
          <dd><a href="/en/0.3.0/">0.3.0</a></dd>
        
          <dd><a href="/en/0.2.0/">0.2.0</a></dd>
        
          <dd><a href="/en/0.1.0/">0.1.0</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/lkpy/?fromdocs=lkpy">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/lkpy/?fromdocs=lkpy">Builds</a>
          </dd>
      </dl>
      <hr>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
   


</body></html>